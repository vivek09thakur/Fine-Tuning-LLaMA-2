{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivek09thakur/Fine-Tuning-LLaMA-2/blob/main/Colab%20Notebook/Fine_Tuning_LLaMA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr7kGZGaWK9_"
      },
      "source": [
        "## **Fine-Tuning LLaMA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dQ-sIIXWK-B"
      },
      "source": [
        "**Installing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rl0sA79FWK-B",
        "outputId": "fa283a2b-1f44-4e0d-907f-ba93089174db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft\n",
            "  Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting trl\n",
            "  Downloading trl-0.7.10-py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Collecting datasets (from trl)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tyro>=0.5.11 (from trl)\n",
            "  Downloading tyro-0.7.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
            "  Downloading shtab-1.6.5-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->trl)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
            "Collecting multiprocess (from datasets->trl)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->trl) (1.16.0)\n",
            "Installing collected packages: shtab, docstring-parser, dill, multiprocess, bitsandbytes, tyro, accelerate, datasets, trl, peft\n",
            "Successfully installed accelerate-0.26.1 bitsandbytes-0.42.0 datasets-2.16.1 dill-0.3.7 docstring-parser-0.15 multiprocess-0.70.15 peft-0.8.2 shtab-1.6.5 trl-0.7.10 tyro-0.7.2\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.5)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "--2024-02-07 22:38:30--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 18.205.222.128, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13921656 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.28M  57.5MB/s    in 0.2s    \n",
            "\n",
            "2024-02-07 22:38:31 (57.5 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13921656/13921656]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate peft bitsandbytes transformers trl\n",
        "!pip install flask-ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "!./ngrok authtoken 2c2CD7vXkTJYULz1dDGFSViTqY9_6KDavnrbYSNxp3TPJReYa # you token here\n",
        "!nohup python -m flask run &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa4ZekUlWK-C"
      },
      "source": [
        "### **Getting Started**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNUwPP3NWK-D"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1irf6Og8WK-F",
        "outputId": "e1f7e114-d2ad-48c8-c559-a0a6dc3d27ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class FineTuned_LlaMA:\n",
        "\n",
        "    def __init__(self,base_model,training_dataset,new_model,num_of_token):\n",
        "        self.base_model = base_model\n",
        "        self.training_dataset = training_dataset\n",
        "        self.new_model = new_model\n",
        "        self.num_of_token = num_of_token\n",
        "        self.dataset = load_dataset(training_dataset, split=\"train\")\n",
        "\n",
        "        # 4-bit quantization config\n",
        "        self.compute_dtype = getattr(torch, \"float16\")\n",
        "        self.quant_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=self.compute_dtype,\n",
        "            bnb_4bit_use_double_quant=False,\n",
        "        )\n",
        "\n",
        "    def load_model(self):\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.base_model,\n",
        "            quantization_config=self.quant_config,\n",
        "            device_map={\"\": 0}\n",
        "        )\n",
        "        self.model.config.use_cache = False\n",
        "        self.model.config.pretraining_tp = 1\n",
        "\n",
        "    def load_tokenizer(self):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.base_model,\n",
        "                                            trust_remote_code=True)\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        self.tokenizer.padding_side = \"right\"\n",
        "\n",
        "        self.peft_params = LoraConfig(\n",
        "                    lora_alpha=16,\n",
        "                    lora_dropout=0.1,\n",
        "                    r=64,\n",
        "                    bias=\"none\",\n",
        "                    task_type=\"CAUSAL_LM\",\n",
        "                )\n",
        "\n",
        "    def model_trainer(self):\n",
        "        self.training_params = TrainingArguments(\n",
        "                        # The output directory is where the model\n",
        "                        # predictions and checkpoints will be stored.\n",
        "                        output_dir=\"./results\",\n",
        "                        num_train_epochs=1, # One training epoch.\n",
        "                        per_device_train_batch_size=4,\n",
        "                        gradient_accumulation_steps=1,\n",
        "                        optim=\"paged_adamw_32bit\",\n",
        "                        save_steps=25,\n",
        "                        logging_steps=25,\n",
        "                        learning_rate=2e-4,\n",
        "                        weight_decay=0.001,\n",
        "                        fp16=False,\n",
        "                        bf16=False,\n",
        "                        max_grad_norm=0.3,\n",
        "                        max_steps=-1,\n",
        "                        warmup_ratio=0.03,\n",
        "                        group_by_length=True,\n",
        "                        lr_scheduler_type=\"constant\",\n",
        "                        report_to=\"tensorboard\"\n",
        "                )\n",
        "\n",
        "        self.trainer = SFTTrainer(\n",
        "            model=self.model,\n",
        "            train_dataset=self.dataset,\n",
        "            peft_config=self.peft_params,\n",
        "            dataset_text_field=\"text\",\n",
        "            max_seq_length=None,\n",
        "            tokenizer=self.tokenizer,\n",
        "            args=self.training_params,\n",
        "            packing=False,\n",
        "        )\n",
        "\n",
        "        self.trainer.model.save_pretrained(self.new_model)\n",
        "        self.trainer.tokenizer.save_pretrained(self.new_model)\n",
        "\n",
        "    def create_pipeline(self):\n",
        "        self.pipe = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=self.model,\n",
        "            tokenizer=self.tokenizer,\n",
        "            max_length=self.num_of_token,\n",
        "        )\n",
        "\n",
        "    def inference(self,prompt):\n",
        "        self.results = self.pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "        return self.results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNlriULqWK-F"
      },
      "source": [
        "### **Driver Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6rS3WjtmWK-G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7770e1ac034b45a2be3488678b0a91b7",
            "fa6128c000da454fa17a8af0461030ca",
            "69309a85df594a9e8886836875ece020",
            "ae325f469e774d358117f3fb68e1478c",
            "df30189e053d404c9e76e47817296151",
            "adbaa9473b1c4a60bfed90060c5ed7ed",
            "4a57722ed4c341c88dd9e024cfebaf8f",
            "28d9bb1577b04ac985f93349b8fea299",
            "4ad8528c4b4c40efa61dd0db4dd5eaa7",
            "150a7256cd964135aad9da6d912b9af9",
            "882f7a56cff746a5a5e0b3a3b251763b"
          ]
        },
        "outputId": "9a986157-8b92-419d-b84e-d8697a8b7311"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7770e1ac034b45a2be3488678b0a91b7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "BASE_MODEL = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "GUANANCO_DATASET = \"mlabonne/guanaco-llama2-1k\"\n",
        "NEW_MODEL = \"llama2-7b-vivek\"\n",
        "TOKENS = 200\n",
        "\n",
        "fine_tuned_model = FineTuned_LlaMA(BASE_MODEL,GUANANCO_DATASET,NEW_MODEL,TOKENS)\n",
        "fine_tuned_model.load_model()\n",
        "fine_tuned_model.load_tokenizer()\n",
        "fine_tuned_model.model_trainer()\n",
        "fine_tuned_model.create_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**main-loop**"
      ],
      "metadata": {
        "id": "xwErZGRAYScW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J5F1vTkFWK-G",
        "outputId": "71b5f721-ab09-4fde-e0ab-9b707a574ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "<You>: hey\n",
            "\n",
            "<LlaMA> :  Hey there! How's it going?\n",
            "Bye!\n",
            "\n",
            "<You>: \n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    try:\n",
        "        prompt = input(\"\\n<You>: \")\n",
        "        prefix = f\"<s>[INST] {prompt} [/INST] \"\n",
        "        response = fine_tuned_model.inference(prompt)[0]['generated_text']\n",
        "        print(f\"\\n<LlaMA> : {response[len(prefix):]}\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Bye!\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**main-app**"
      ],
      "metadata": {
        "id": "qpAfSd8NvVH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask,request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"<h1>Server Looks Good!</h1>\"\n",
        "\n",
        "@app.route('/generate_response', methods=['POST'])\n",
        "def receive_data():\n",
        "    data = request.get_json()\n",
        "    prompt = data['key']\n",
        "    prefix = f\"<s>[INST] {prompt} [/INST] \"\n",
        "    response = fine_tuned_model.inference(prompt)[0]['generated_text']\n",
        "    cleaned_response = response[len(prefix):]\n",
        "    return cleaned_response, 200"
      ],
      "metadata": {
        "id": "Mk47VLMRuj2Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.run()"
      ],
      "metadata": {
        "id": "EvIdIBA1L0rm",
        "outputId": "e8362b2c-a4a7-45f9-8830-5b4349a29844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://b195-35-231-41-208.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 22:54:25] \"POST /generate_response HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 22:55:12] \"POST /generate_response HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 22:56:44] \"POST /generate_response HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 22:58:44] \"POST /generate_response HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 23:00:53] \"POST /generate_response HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 23:03:10] \"POST /generate_response HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 23:03:53] \"POST /generate_response HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 23:07:35] \"POST /generate_response HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 23:11:01] \"POST /generate_response HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Feb/2024 23:12:17] \"POST /generate_response HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7770e1ac034b45a2be3488678b0a91b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa6128c000da454fa17a8af0461030ca",
              "IPY_MODEL_69309a85df594a9e8886836875ece020",
              "IPY_MODEL_ae325f469e774d358117f3fb68e1478c"
            ],
            "layout": "IPY_MODEL_df30189e053d404c9e76e47817296151"
          }
        },
        "fa6128c000da454fa17a8af0461030ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adbaa9473b1c4a60bfed90060c5ed7ed",
            "placeholder": "​",
            "style": "IPY_MODEL_4a57722ed4c341c88dd9e024cfebaf8f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "69309a85df594a9e8886836875ece020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28d9bb1577b04ac985f93349b8fea299",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ad8528c4b4c40efa61dd0db4dd5eaa7",
            "value": 2
          }
        },
        "ae325f469e774d358117f3fb68e1478c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_150a7256cd964135aad9da6d912b9af9",
            "placeholder": "​",
            "style": "IPY_MODEL_882f7a56cff746a5a5e0b3a3b251763b",
            "value": " 2/2 [01:11&lt;00:00, 32.52s/it]"
          }
        },
        "df30189e053d404c9e76e47817296151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbaa9473b1c4a60bfed90060c5ed7ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a57722ed4c341c88dd9e024cfebaf8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28d9bb1577b04ac985f93349b8fea299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad8528c4b4c40efa61dd0db4dd5eaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "150a7256cd964135aad9da6d912b9af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "882f7a56cff746a5a5e0b3a3b251763b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}